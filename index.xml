<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>My New Hugo Site</title>
    <link>https://xh306.github.io/</link>
    <description>Recent content on My New Hugo Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 09 Feb 2020 20:31:25 +0800</lastBuildDate>
    
	<atom:link href="https://xh306.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>消息中间件</title>
      <link>https://xh306.github.io/post/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/</link>
      <pubDate>Sun, 09 Feb 2020 20:31:25 +0800</pubDate>
      
      <guid>https://xh306.github.io/post/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/</guid>
      <description>1.1什么是消息中间件 消息 (Message) 是指在应用间传送的数据。消息可以非常简单，比如只包含文本字符串、
JSON 等，也可以很复杂，比如内嵌对象。
消息队列中间件，也可以称为消息队列或者消息中间件。它一般有两种传递模式:点对点
(p2p,Point-to-Point) 模式和发布/订阅 (Pub/Sub) 模式。点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息，队列的存在使得消息的异步传输成为可能。
布订阅模式定义了如何向 个内容节点发布和订阅消息，这个内容节点称为主题 (topic) ，主
题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者则从主题中
订阅消息。主题使得消息的订阅者与消息的发布者互相保持独立，不需要进行接触即可保证消
息的传递，发布/订阅模式在消息的一对多广播时采用
消息中间件将消息路由给应用程序 ，这样消息就可存在于完全不同的计算机上。消息中
间件负责处理网络通信，如果网络连接不可用，消息 中间件会存储消息 ，直到连接变得可用，
再将消息转发给应用程序 。灵活性的另一方面体现在，当应用程序 发送其消息时，应用程
序B甚至可以处于不运行状态，消息中间件将保留这份消息，直到应用程序 开始执行并消费
消息，这样还防止了应用程序 因为等待应用程序 消费消息而出现阻塞。这种异步通信方式
要求应用程序的设计与现在大多数应用不同。不过对于时间无关或并行处理的场景，它可能是
个极其有用的方法
1.2消息中间件的作用 ​	消息中间件凭借其独到的特性，在不同的应用场景下可以展现不同的作用 。总 的来说，消
息中间件的作用可以概括如下。
​	解耦:在项目启动之初来预测将来会碰到什么需求是极其困难的。消息中间件在处理过程
中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口，这允许你独
立地扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束即可 。
​	冗余〈存储) 有些情况下，处理数据的过程会失败。消息中间件可以把数据进行持久化直
到它们已经被完全处理，通过这一方式规避了数据丢失风险。在把 个消息从消息中间件中删
除之前，需要你的处理系统明确地指出该消息己经被处理完成，从而确保你的数据被安全地保
存直到你使用完毕。
​	扩展性: 因为消息中间件解捐了应用的处理过程，所以提高消息入队和处理的效率是很容
易的，只要另外增加处理过程即可，不需要改变代码，也不需要调节参数。
​	削峰: 在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流 并不常
见。如果以能处理这类峰值为标准而投入资源，无疑是巨大的浪费 使用消息中间件能够使关
键组件支撑突发访问压力，不会因为突发的超负荷请求而完全崩惯
​	可恢复性: 当系统一部分组件失效时，不会影响到整个系统 消息中间件降低了进程间的
稿合度，所以即使 个处理消息的进程挂掉，加入消息中间件中的消息仍然可以在系统恢复后
进行处理
​	顺序保证: 在大多数使用场景下，数据处理的顺序很重要，大部分消息中间件支持 定程</description>
    </item>
    
    <item>
      <title>Redis深度学习</title>
      <link>https://xh306.github.io/post/redis%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Sun, 09 Feb 2020 20:31:09 +0800</pubDate>
      
      <guid>https://xh306.github.io/post/redis%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</guid>
      <description>Redis为什么查询那么快？ Redis安装在磁盘，数据是基于内存条存储的
Redis特性 1）速度快
Redis基于内存条的存储读取
2）键值对的数据结构服务器
key它永远是一个字符串，value支持String、hash、list、set、zset类型存储
3）丰富的功能
对多类语言提供了API,例如php、c#
4）简单稳定
主线程是单线程
5）持久化
内存的数据实时备份到磁盘，内存的数据持久到磁盘。
6) 主从复制
24小时不间断运行，例如A服务崩溃B服务可代替工作，客户端语言很多。对Java而言提供了一个很有用的api类Jedis
8）高可用和分布式转移
9）客户端语言多
支持Java、PHP、C#、Erlang等等多门语言
缓存穿透 当用户发送请求，程序先查询Redis缓存有没有数据，如果没有则去数据库查询，我们称之为Redis穿透
缓存穿透方案当发起请求时，先经过布隆过滤器，如果布隆过滤器不存在该值(false)，则不允许查询数据库并返回非法参数结果，如果存在该值(true)则允许查询数据库
Redis使用场景
1.缓存数据库
2.排行榜
3.计数器应用
4.社交网络
5.消息队列
1.雪崩效应
假如有5000个用户并发(发出同一个查询请求)，去查询key=james的值，此时Redis缓存中没有数据，那么这五千个请求就会到数据库去查询，数据库的吞吐量小，那么就会造成雪崩效应。
解决方案：利用锁的机制，在程序启动时只允许单个线程（请求）查询数据库，其它4999个请求等待中，当查询到了结果，将结果存放到Redis缓存中并返回，而后其它4999个请求直接读取Redis缓存中key=james的值</description>
    </item>
    
    <item>
      <title>分布式锁的那些事</title>
      <link>https://xh306.github.io/post/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/</link>
      <pubDate>Sun, 09 Feb 2020 20:30:34 +0800</pubDate>
      
      <guid>https://xh306.github.io/post/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/</guid>
      <description>为什么要用到锁？
多任务环境中才需要
任务都需要对同一共享资源进行写操作
对资源的访问时互斥的(任务不能够同一时间访问资源)
锁的生命周期
​	Tips:(①竞争锁)任务通过竞争取锁才能对该资源进行操作;
​	(②占有锁)当有一个任务在对资源进行更新时；
​	(③任务阻塞)其他任务都不可以对这个资源进行操作
​	(④释放锁)直到该任务完成更新
jdk锁的那些事 ​	相比synchronized而言，其实Java有个使用起来更加方便且实用的锁Lock(ReentrantLock)，Lock接口提供了lock()、lockInterruptibly()、tryLock()、unlock()等方法，同时也体现了Lock锁的灵活性。
lock()：阻塞式加锁(死缠烂打加锁型)
lockInterruptibly()：可中断式阻塞加锁(可以根据特定的条件中断阻塞)
tryLock()：加一次锁，加成功了返回true，失败了返回false
unlock()：根据些条件解锁
加锁解锁</description>
    </item>
    
    <item>
      <title>聊聊常见的数据库架构设计方案？</title>
      <link>https://xh306.github.io/post/database/</link>
      <pubDate>Tue, 07 Jan 2020 16:19:34 +0800</pubDate>
      
      <guid>https://xh306.github.io/post/database/</guid>
      <description>一、数据库架构原则
1.高可用
2.高性能
3.一致性
4.扩展性
二、常见的数据库架构方案 方案一：主备架构，只有主库提供读写服务，备库冗余作故障转移用 jdbc:mysql://vip:3306/xxdb
1、**高可用分析：**高可用，主库挂了，keepalive（只是一种工具）会自动切换到备库。这个过程对业务层是透明的，无需修改代码或配置。
2、**高性能分析：**读写都操作主库，很容易产生瓶颈。大部分互联网应用读多写少，读会先成为瓶颈，进而影响写性能。另外，备库只是单纯的备份，资源利用率50%，这点方案二可解决。
3、**一致性分析：**读写都操作主库，不存在数据一致性问题。
4、**扩展性分析：**无法通过加从库来扩展读性能，进而提高整体性能。
5、可落地分析：两点影响落地使用。第一，性能一般，这点可以通过建立高效的索引和引入缓存来增加读性能，进而提高性能。这也是通用的方案。第二，扩展性差，这点可以通过分库分表来扩展。
方案二：双主架构，两个主库同时提供服务，负载均衡 jdbc:mysql://vip:3306/xxdb
1、**高可用分析：**高可用，一个主库挂了，不影响另一台主库提供服务。这个过程对业务层是透明的，无需修改代码或配置。
2、**高性能分析：**读写性能相比于方案一都得到提升，提升一倍。
3、**一致性分析：**存在数据一致性问题。请看，一致性解决方案。
4、扩展性分析：当然可以扩展成三主循环，但笔者不建议（会多一层数据同步，这样同步的时间会更长）。如果非得在数据库架构层面扩展的话，扩展为方案四。
5、**可落地分析：两点影响落地使用。第一，数据一致性问题，一致性解决方案可解决问题。**第二，主键冲突问题，ID统一地由分布式ID生成服务来生成可解决问题。
方案三：主从架构，一主多从，读写分离 jdbc:mysql://master-ip:3306/xxdb
jdbc:mysql://slave1-ip:3306/xxdb
jdbc:mysql://slave2-ip:3306/xxdb
1、**高可用分析：**主库单点，从库高可用。一旦主库挂了，写服务也就无法提供。
2、**高性能分析：**大部分互联网应用读多写少，读会先成为瓶颈，进而影响整体性能。读的性能提高了，整体性能也提高了。
另外，主库可以不用索引，线上从库和线下从库也可以建立不同的索引
（线上从库如果有多个还是要建立相同的索引，不然得不偿失；线下从库是平时开发人员排查线上问题时查的库，可以建更多的索引）
3、**一致性分析：**存在数据一致性问题。请看，一致性解决方案。
4、**扩展性分析：**可以通过加从库来扩展读性能，进而提高整体性能。
（带来的问题是，从库越多需要从主库拉取binlog日志的端就越多，进而影响主库的性能，并且数据同步完成的时间也会更长）
5、**可落地分析：两点影响落地使用。第一，数据一致性问题，一致性解决方案可解决问题。**第二，主库单点问题，笔者暂时没想到很好的解决方案。
注：思考一个问题，一台从库挂了会怎样？读写分离之读的负载均衡策略怎么容错？
方案四：双主+主从架构，看似完美的方案 dbc:mysql://vip:3306/xxdb
jdbc:mysql://slave1-ip:3306/xxdb
jdbc:mysql://slave2-ip:3306/xxdb
1、**高可用分析：**高可用。
2、**高性能分析：**高性能。
3、**一致性分析：**存在数据一致性问题。请看，一致性解决方案 。
4、扩展性分析：可以通过加从库来扩展读性能，进而提高整体性能。（带来的问题同方案二）
5、可落地分析：同方案二，但数据同步又多了一层，数据延迟更严重**。**
三、一致性解决方案 第一类：主库和从库一致性解决方案 注：图中圈出的是数据同步的地方，数据同步（从库从主库拉取binlog日志，再执行一遍）是需要时间的，这个同步时间内主库和从库的数据会存在不一致的情况。如果同步过程中有读请求，那么读到的就是从库中的老数据。
如下图
既然知道了数据不一致性产生的原因，有下面几个解决方案供参考：
1、直接忽略，如果业务允许延时存在，那么就不去管它。
2、强制读主，采用主备架构方案，读写都走主库。用缓存来扩展数据库读性能 。有一点需要知道：如果缓存挂了，可能会产生雪崩现象，不过一般分布式缓存都是高可用的。
3、选择读主，写操作时根据库+表+业务特征生成一个key放到Cache里并设置超时时间（大于等于主从数据同步时间）。
读请求时，同样的方式生成key先去查Cache，再判断是否命中。若命中，则读主库，否则读从库。代价是多了一次缓存读写，基本可以忽略。
4、半同步复制，等主从同步完成，写请求才返回。就是大家常说的“半同步复制”semi-sync。这可以利用数据库原生功能，实现比较简单。代价是写请求时延增长，吞吐量降低。
5、数据库中间件，引入开源（mycat等）或自研的数据库中间层。个人理解，思路同**选择读主。数据库中间件的成本比较高，并且还多引入了一层。
第二类：DB和缓存一致性解决方案 先来看一下常用的缓存使用方式：
第一步：淘汰缓存；
第二步：写入数据库；
第三步：读取缓存？返回：读取数据库；
第四步：读取数据库后写入缓存。
注：如果按照这种方式，图一，不会产生DB和缓存不一致问题；图二，会产生DB和缓存不一致问题，即4.read先于3.sync执行。如果不做处理，缓存里的数据可能一直是脏数据。解决方式如下：
注：设置缓存时，一定要加上有效时间，以防延时淘汰缓存失败的情况！
四、个人的一些见解 1、架构演变 1、架构演变一：方案一 -&amp;gt; 方案一+分库分表 -&amp;gt; 方案二+分库分表 -&amp;gt; 方案四+分库分表；</description>
    </item>
    
    <item>
      <title>关于博主</title>
      <link>https://xh306.github.io/post/me/</link>
      <pubDate>Thu, 26 Dec 2019 15:32:25 +0800</pubDate>
      
      <guid>https://xh306.github.io/post/me/</guid>
      <description>特别感谢 up主 CodeSheep Hi 欢迎来到我的博客，我叫谢辉，其实我在很早之前就想搭建属于自己的个人博客了，
但一直都没有时间去查阅相关资料，大家也想搭建个人博客可以点击上方的链接，他的干货很多终于在今天搭建好了，希望日后能够一起学习一进步哈哈，
第一次写博客有点小紧张哈哈</description>
    </item>
    
    <item>
      <title>SpringCloud相关面试题</title>
      <link>https://xh306.github.io/post/blog/</link>
      <pubDate>Thu, 26 Dec 2019 14:38:14 +0800</pubDate>
      
      <guid>https://xh306.github.io/post/blog/</guid>
      <description>面试官:HashMap里面的hashcode有什么作用 返回对象的哈希码值（就是散列码），用来支持哈希表，：例如HashMap 可以提高哈希表的性能。 面试官:项目中异常怎么设计的 有的利用模板模式 有的利用spring的拦截器
面试官:SpringBoot和SpringCloud有什么区别 SpringBoot专注于快速方便的开发单个个体微服务。 SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot 开发的一个个单体微服务整合并管理起来， 为各个服务之间提供，配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、精选决策、分布式会话等集成服务。 SpringBoot可以离开SpringCloud独立开发项目，但SpringCloud离不开SpringBoot ，属于依赖关系。 SpringBoot专注于快速，方便开发单个微服务个体，SpringCloud关注全局的服务治理框架。
面试官:项目为什么用springCloud ​	SpringCloud来源于Spring，质量、稳定性、持续性都可以得到保证。 ​	SpringCloud天然支持SpringBoot，更加便于业务落地。 ​	SpringCloud发展的非常快，从16开始接触的时候相关组件版本为1.x，现在将要发布2.x系列。 ​	SpringCloud是Java领域最适合做微服务的框架。 ​	相比于其它框架，SpringCloud对微服务周边环境的支持力度最大。对中小企业来讲，使用门槛更低。
面试官:消息队列MQ怎么保证数据不重复 怎么保证消息队列消费的幂等性： 比如数据写库，可以先根据主键查一下，如果这数据都有了，就update 如果不是上面两个场景，那做的稍微复杂一点，需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后消费到了后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，就处理，然后这个id写redis。如果消费过了，那就别处理了，保证别重复处理相同的消息即可。 还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据 这里我推荐利用数据库中的唯一键约束 特性,天然的幂等 防止重复请求这个问题和MQ消费重复数据有点重复了 普通防止重复请求 当然这个requestId 会落地DB表并且requestId是唯一约束,面试的时候幂等问题 你能讲出具体类的设计 表的设计 就完美了</description>
    </item>
    
  </channel>
</rss>